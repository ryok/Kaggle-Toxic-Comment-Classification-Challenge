{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット読み込み\n",
    "#train = pd.read_csv('/root/userspace/final/Kaggle-Toxic-Comment-Classification-Challenge/input/train.csv')\n",
    "#test = pd.read_csv('/root/userspace/final/Kaggle-Toxic-Comment-Classification-Challenge/input/test.csv')\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "train = train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 念のため、コメント部分のnullがある場合は特定の文字列に置換\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"ryok\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"ryok\").values\n",
    "\n",
    "# テストデータのサイズ（量）\n",
    "vocab_size = len(list_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenizerによる文字列の数値化\n",
    "tokenizer = text.Tokenizer(num_words=max_features) # データセット中の頻度上位num_wordsの単語に制限\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "\n",
    "# maxlenにpaddingし、長さを揃える\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    embed_size = 128\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "batch_size = 32 # バッチサイズ？なぜ\n",
    "epochs = 50 #エポック数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの保存設定\n",
    "file_path=\"weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# 早期終了（最低ループ20回）\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 7979 samples\n",
      "Epoch 1/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9793Epoch 00001: val_loss improved from inf to 0.04070, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.983561 \n",
      "\n",
      "159571/159571 [==============================] - 1397s 9ms/step - loss: 0.0618 - acc: 0.9793 - val_loss: 0.0407 - val_acc: 0.9846\n",
      "Epoch 2/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9833Epoch 00002: val_loss improved from 0.04070 to 0.03551, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.990569 \n",
      "\n",
      "159571/159571 [==============================] - 1373s 9ms/step - loss: 0.0446 - acc: 0.9833 - val_loss: 0.0355 - val_acc: 0.9869\n",
      "Epoch 3/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9851Epoch 00003: val_loss improved from 0.03551 to 0.03043, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.994587 \n",
      "\n",
      "159571/159571 [==============================] - 1371s 9ms/step - loss: 0.0384 - acc: 0.9851 - val_loss: 0.0304 - val_acc: 0.9888\n",
      "Epoch 4/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9869Epoch 00004: val_loss improved from 0.03043 to 0.02609, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.996221 \n",
      "\n",
      "159571/159571 [==============================] - 1370s 9ms/step - loss: 0.0330 - acc: 0.9869 - val_loss: 0.0261 - val_acc: 0.9902\n",
      "Epoch 5/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9885Epoch 00005: val_loss improved from 0.02609 to 0.02123, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.997258 \n",
      "\n",
      "159571/159571 [==============================] - 1375s 9ms/step - loss: 0.0288 - acc: 0.9885 - val_loss: 0.0212 - val_acc: 0.9920\n",
      "Epoch 6/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9900Epoch 00006: val_loss improved from 0.02123 to 0.01853, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.997910 \n",
      "\n",
      "159571/159571 [==============================] - 1377s 9ms/step - loss: 0.0248 - acc: 0.9900 - val_loss: 0.0185 - val_acc: 0.9934\n",
      "Epoch 7/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9913Epoch 00007: val_loss improved from 0.01853 to 0.01464, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.998686 \n",
      "\n",
      "159571/159571 [==============================] - 1378s 9ms/step - loss: 0.0215 - acc: 0.9913 - val_loss: 0.0146 - val_acc: 0.9947\n",
      "Epoch 8/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9926Epoch 00008: val_loss improved from 0.01464 to 0.01257, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.999099 \n",
      "\n",
      "159571/159571 [==============================] - 1373s 9ms/step - loss: 0.0186 - acc: 0.9926 - val_loss: 0.0126 - val_acc: 0.9953\n",
      "Epoch 9/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9937Epoch 00009: val_loss improved from 0.01257 to 0.01076, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.999323 \n",
      "\n",
      "159571/159571 [==============================] - 1373s 9ms/step - loss: 0.0161 - acc: 0.9937 - val_loss: 0.0108 - val_acc: 0.9961\n",
      "Epoch 10/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9944Epoch 00010: val_loss improved from 0.01076 to 0.00914, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.999485 \n",
      "\n",
      "159571/159571 [==============================] - 1374s 9ms/step - loss: 0.0142 - acc: 0.9944 - val_loss: 0.0091 - val_acc: 0.9967\n",
      "Epoch 11/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9950Epoch 00011: val_loss improved from 0.00914 to 0.00812, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.999610 \n",
      "\n",
      "159571/159571 [==============================] - 1370s 9ms/step - loss: 0.0126 - acc: 0.9950 - val_loss: 0.0081 - val_acc: 0.9971\n",
      "Epoch 12/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9956Epoch 00012: val_loss improved from 0.00812 to 0.00742, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.999633 \n",
      "\n",
      "159571/159571 [==============================] - 1370s 9ms/step - loss: 0.0114 - acc: 0.9956 - val_loss: 0.0074 - val_acc: 0.9972\n",
      "Epoch 13/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9960Epoch 00013: val_loss improved from 0.00742 to 0.00665, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.999709 \n",
      "\n",
      "159571/159571 [==============================] - 1369s 9ms/step - loss: 0.0103 - acc: 0.9960 - val_loss: 0.0067 - val_acc: 0.9974\n",
      "Epoch 14/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9964Epoch 00014: val_loss improved from 0.00665 to 0.00558, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 14 - score: 0.999754 \n",
      "\n",
      "159571/159571 [==============================] - 1375s 9ms/step - loss: 0.0093 - acc: 0.9964 - val_loss: 0.0056 - val_acc: 0.9978\n",
      "Epoch 15/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9966Epoch 00015: val_loss improved from 0.00558 to 0.00534, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 15 - score: 0.999802 \n",
      "\n",
      "159571/159571 [==============================] - 1372s 9ms/step - loss: 0.0088 - acc: 0.9966 - val_loss: 0.0053 - val_acc: 0.9980\n",
      "Epoch 16/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9969Epoch 00016: val_loss improved from 0.00534 to 0.00509, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 16 - score: 0.999819 \n",
      "\n",
      "159571/159571 [==============================] - 1367s 9ms/step - loss: 0.0081 - acc: 0.9969 - val_loss: 0.0051 - val_acc: 0.9981\n",
      "Epoch 17/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9970Epoch 00017: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 17 - score: 0.999832 \n",
      "\n",
      "159571/159571 [==============================] - 1373s 9ms/step - loss: 0.0076 - acc: 0.9970 - val_loss: 0.0051 - val_acc: 0.9981\n",
      "Epoch 18/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9973Epoch 00018: val_loss improved from 0.00509 to 0.00440, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 18 - score: 0.999896 \n",
      "\n",
      "159571/159571 [==============================] - 1370s 9ms/step - loss: 0.0071 - acc: 0.9973 - val_loss: 0.0044 - val_acc: 0.9984\n",
      "Epoch 19/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9975Epoch 00019: val_loss improved from 0.00440 to 0.00389, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 19 - score: 0.999910 \n",
      "\n",
      "159571/159571 [==============================] - 1373s 9ms/step - loss: 0.0066 - acc: 0.9975 - val_loss: 0.0039 - val_acc: 0.9986\n",
      "Epoch 20/50\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9976Epoch 00020: val_loss improved from 0.00389 to 0.00337, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 20 - score: 0.999935 \n",
      "\n",
      "159571/159571 [==============================] - 1372s 9ms/step - loss: 0.0062 - acc: 0.9976 - val_loss: 0.0034 - val_acc: 0.9987\n",
      "Epoch 21/50\n",
      " 30304/159571 [====>.........................] - ETA: 18:10 - loss: 0.0049 - acc: 0.9982"
     ]
    }
   ],
   "source": [
    "X_tra, X_val, y_tra, y_val = train_test_split(X_t, y, train_size=0.95, random_state=1)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "callbacks_list = [checkpoint, early, RocAuc]\n",
    "try:\n",
    "    # 交差検定\n",
    "    history = model.fit(\n",
    "        X_t, y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        #validation_split=0.2,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossのプロット\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accのプロット\n",
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# テストデータに対して予測実施\n",
    "model.load_weights(file_path)\n",
    "y_test = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample_submission = pd.read_csv(\"/root/userspace/final/Kaggle-Toxic-Comment-Classification-Challenge/input/sample_submission.csv\")\n",
    "sample_submission = pd.read_csv(\"./input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = y_test\n",
    "#sample_submission.to_csv(\"/root/userspace/final/Kaggle-Toxic-Comment-Classification-Challenge/baseline.csv\", index=False)\n",
    "sample_submission.to_csv(\"./baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
