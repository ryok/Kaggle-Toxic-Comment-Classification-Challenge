{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データセット読み込み\n",
    "train = pd.read_csv(\"./input/train.csv\")\n",
    "test = pd.read_csv(\"./input/test.csv\")\n",
    "\n",
    "# サンプリング（割合100%）\n",
    "train = train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 念のため、コメント部分のnullがある場合は特定の文字列に置換\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"unknown\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"unknown\").values\n",
    "\n",
    "# テストデータのサイズ（量）\n",
    "vocab_size = len(list_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizerによる文字列の数値化\n",
    "tokenizer = text.Tokenizer(num_words=max_features) # データセット中の頻度上位num_wordsの単語に制限\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "\n",
    "# maxlenにpaddingし、長さを揃える\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    embed_size = 128 # embeddingのoutputサイズ\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = LSTM(60, return_sequences=True, name='lstm_layer')(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 200, 60)           45360     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 2,608,716\n",
      "Trainable params: 2,608,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "batch_size = 32 # バッチサイズ\n",
    "epochs = 10 # エポック数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの保存設定\n",
    "file_path=\"weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# 早期終了\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)\n",
    "\n",
    "#X_tra, X_val, y_tra, y_val = train_test_split(X_t, y, train_size=0.95, random_state=1)\n",
    "X_tra, X_test, y_tra, y_test = train_test_split(X_t, y, train_size=0.95, random_state=1)\n",
    "#RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121273 samples, validate on 30319 samples\n",
      "Epoch 1/2\n",
      "121248/121273 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9772Epoch 00001: val_loss improved from inf to 0.04925, saving model to weights_base.best.hdf5\n",
      "121273/121273 [==============================] - 1140s 9ms/step - loss: 0.0706 - acc: 0.9772 - val_loss: 0.0493 - val_acc: 0.9819\n",
      "Epoch 2/2\n",
      "121248/121273 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9830Epoch 00002: val_loss improved from 0.04925 to 0.04737, saving model to weights_base.best.hdf5\n",
      "121273/121273 [==============================] - 1136s 9ms/step - loss: 0.0459 - acc: 0.9830 - val_loss: 0.0474 - val_acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 交差検定\n",
    "    history = model.fit(\n",
    "        X_tra, y_tra,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        #validation_data=(X_val, y_val),\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.046626410742\n",
      "Test accuracy: 0.983477447726\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       verbose=0\n",
    "                       )\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Some plots\n",
    "# ----------------------------------------------\n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "# loss\n",
    "def plot_history_loss(fit):\n",
    "    # Plot the loss in the history\n",
    "    axL.plot(fit.history['loss'],label=\"loss for training\")\n",
    "    axL.plot(fit.history['val_loss'],label=\"loss for validation\")\n",
    "    axL.set_title('model loss')\n",
    "    axL.set_xlabel('epoch')\n",
    "    axL.set_ylabel('loss')\n",
    "    axL.legend(loc='upper right')\n",
    "\n",
    "# acc\n",
    "def plot_history_acc(fit):\n",
    "    # Plot the loss in the history\n",
    "    axR.plot(fit.history['acc'],label=\"acc for training\")\n",
    "    axR.plot(fit.history['val_acc'],label=\"acc for validation\")\n",
    "    axR.set_title('model accuracy')\n",
    "    axR.set_xlabel('epoch')\n",
    "    axR.set_ylabel('accuracy')\n",
    "    axR.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_history_loss(history)\n",
    "plot_history_acc(history)\n",
    "fig.savefig('./pattern1.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
